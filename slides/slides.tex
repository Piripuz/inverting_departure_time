\documentclass{beamer}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{graphicx}
\graphicspath{ {./img/} }

\usetheme{default}

\title{Inverting Vickrey}

\begin{document}

\begin{frame}{\titlepage}
  
\end{frame}

\begin{frame}{The setting}
  \only<-2>{
    We are assuming, as in (cite something) the cost function to be
    \begin{equation}
      \label{eq:cost}
      C(t_d) = \alpha tt(t_d) + \beta[t^*-t_d-tt(t_d)]^+ + \gamma[t_d+tt(t_d)-t^*]^+ 
    \end{equation}
  }
    \only<1>{
      where
      \begin{itemize}
      \item \(t^*\) is the desired arrival time
      \item \(\alpha\) is the value of time spent travelling
      \item \(\beta\) is the value of time spent waiting there
      \item \(\gamma\) is the value of time arriving late
      \item \(tt(t_d)\) is the expected (exogenous) travel time if leaving at time \(t_d\).
      \item \([x]^+ = \max(0, x)\)
      \end{itemize}
    }
    \only<2>{
      Without loss of generality, we can assume \(\alpha = 1\).

      Moreover, by defining the arrival time
      \begin{equation*}
        t_a = t_d + tt(t_d)
      \end{equation*}
      equation \eqref{eq:cost} becomes thus
    }
    \uncover<2->{
      \begin{equation}
        \label{eq:cost_ta}
        C(t_a) = tt_a(t_a) + \beta[t^*-t_a]^+ + \gamma[t_a-t^*]^+
      \end{equation}
    }
    \uncover<3>{
      We now assume the parameters \(\beta\), \(\gamma\) and the desired arrival times \(t^*\) to be normally distributed:
      \begin{itemize}
      \item \(\beta \sim \mathcal{N}(\mu_\beta, \sigma)\)
      \item \(\gamma \sim \mathcal{N}(\mu_\gamma, \sigma)\)
      \item \(t^* \sim \mathcal{N}(\mu_t, \sigma_t)\)
      \end{itemize}
    }
\end{frame}

\begin{frame}{Optimal arrival time samples}
  
  \begin{columns}
    \column{.4\linewidth}
      Drawing samples from these distributions, using a typical travel time function \(tt(t_a)\), the optima will be (in general) distributed as in the image,
      where the green and red zones roughly correspond to, respectively, early and late arrivals.

      Note that the x axis is random white noise, to better display the data distribution.
      
    \column{.6\linewidth}
    \centering
      \includegraphics[width=\textwidth]{t_as}
  \end{columns}
\end{frame}

\begin{frame}{Optimal arrival time samples}
  As can be seen here, the early and late arrival are strictly correlated to the shape of the travel time function.
  \begin{center}
    \includegraphics[width=\textwidth]{t_as_bins_tt}
  \end{center}
\end{frame}

\begin{frame}{Methodology}
  Our goal is thus finding, from the data about actual arrival times, the most likely values of mean and variances of the parameters \(\beta\) and \(\gamma\), on top of mean and variance for the desired arrival time \(t^*\).

  This was done by modelling the actual likelihood of each data point for a given parameter set
  \begin{equation*}
    \mathcal{L}(\mu_\beta, \mu_\gamma, \mu_t, \sigma, \sigma_t\ \vert\ T_a = t_a) =
  f_{T_a; \mu_\beta, \mu_\gamma, \mu_t, \sigma, \sigma_t}(t_a)
  \end{equation*}
  where \(f_{T_a; \theta}\) is the probability density function for the random variable \(T_a\),
  which describes the resulting optimal arrival time (namely, the one depicted in the plots above), given the parameters \(\theta\).
  
  Once the likelihood function is built, running an optimizer on the total likelihood of the dataset retrieves the true parameters for a given dataset.
\end{frame}

\begin{frame}{Building the likelihood function}
  To build the likelihood function, each point is assigned a probability of being an early, late or on time arrival.

  This is done by taking advantage of the key observation that early and late arrivals only occur when the desired arrival time \(t^*\) falls in certain zones defined by the parameters \(\alpha\) and \(\gamma\), namely the shaded zones in the plot below

  \begin{center}
    \includegraphics[width=.9\textwidth]{tt_early_late}
  \end{center}
\end{frame}

\begin{frame}{Building the likelihood function}
  This observation allows us to define a likelihood function:
  as can be seen below, given the actual parameters the empirical distribution arising from sampling data and directly minimizing the cost function \(C(t_a)\) is well described by our likelihood function

  \begin{center}
    \alt<2>{\includegraphics[width=.9\textwidth]{hist_ll}}{\includegraphics[width=.9\textwidth]{hist_no_ll}}
  \end{center}
\end{frame}

\begin{frame}{Computation of the likelihood function}
  Computing the likelihood \(\mathcal{L}(\mu_\beta, \mu_\gamma, \mu_t, \sigma, \sigma_t\ \vert\ T_a = t_a)\) is computationally not trivial, since it requires to invert various functions and to compute different integrals.

  It was made possible by extensively using the python library JAX (cite JAX paper), which considerably sped up the calculations (by different orders of magnitude) and allowed us to have a fast enough likelihood function to be able to run an optimizer over it.

  Moreover, the library JAXopt (cite JAXopt paper)  would allow us to run a Gradient Descent algorithm over the total likelihood.
  For problems with numerical stability, this approach is not fully developed yet, but will be explored in the future.
\end{frame}

\begin{frame}{Properties of the likelihood function}
  Contour plots for the likelihood functions (that is, given the data, defined on \(\mathbb{R}^5\)) are possible by freezing some of the parameters to their true value,
  and evaluating the likelihood of a synthetic dataset generated with the given parameters.

  By plotting the mean parameters \(\mu_\beta, \mu_\gamma\) it can be seen how the likelihood is better behaved when the variance \(\sigma\) is not too low:

  a low value for the variance could yield indeed a local minimum for a different value of the mean \(\mu_\gamma\).
  
\end{frame}

\begin{frame}{Changing the variance of the parameters \(\beta\), \(\gamma\)}
  \only<-2>{With variances that are neither too high nor too low,
  the likelihood function is well behaved, and the optimizers show no problems in converging:

  Here is the likelihood for variance \alt<2>{\(\sigma = 0.03\)}{\(\sigma = 0.3\)}}

  \begin{center}
    \alt<-1>{\includegraphics[width=.9\textwidth]{contour_beautiful}}{\includegraphics[width=.8\textwidth]{contour_ugly}}
  \end{center}

  \only<3->{
    It can be seen how the likelihood is almost constant in \(\mu_\gamma\), and thus problematic to optimize.

    There actually is a sharp minimum in the real parameters, but it is so sharp that it is difficult to see, and often smaller than the grid used for plotting the contour.
  }
\end{frame}

\end{document}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:
